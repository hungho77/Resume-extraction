# Resume Parser with DocLing and Qwen3-8B

A powerful document parser that extracts structured information from resumes using DocLing for document processing and Qwen3-8B for LLM enhancement.

## ğŸ—ï¸ Project Structure

```
Resume-extraction/
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ core/              # Core modules
â”‚   â”‚   â”œâ”€â”€ config.py      # Configuration management
â”‚   â”‚   â”œâ”€â”€ document_processor.py  # Document processing logic
â”‚   â”‚   â””â”€â”€ llm_client.py  # LLM integration
â”‚   â”œâ”€â”€ api/               # API related
â”‚   â”‚   â””â”€â”€ server.py      # FastAPI server
â”‚   â””â”€â”€ utils/             # Utilities
â”œâ”€â”€ scripts/               # Executable scripts
â”‚   â”œâ”€â”€ vllm_server.py    # vLLM server script
â”‚   â”œâ”€â”€ main.py           # CLI interface
â”‚   â””â”€â”€ start_servers.sh  # Server startup script
â”œâ”€â”€ tests/                 # Test files
â”‚   â”œâ”€â”€ test_qwen_resume.py
â”‚   â”œâ”€â”€ test_example.py
â”‚   â””â”€â”€ example_usage.py
â”œâ”€â”€ docs/                  # Documentation
â”‚   â”œâ”€â”€ README.md         # Detailed documentation
â”‚   â””â”€â”€ SETUP.md          # Setup guide
â””â”€â”€ requirements.txt
```

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Start Servers
```bash
# Start both vLLM and API servers
bash scripts/start_servers.sh

# Or start only vLLM server
bash scripts/start_servers.sh --vllm-only

# Or start only API server
bash scripts/start_servers.sh --api-only
```

### 3. Test the System
```bash
# Test with Qwen3-8B
python tests/test_qwen_resume.py

# Use CLI interface
python scripts/main.py --help
```

## ğŸ”§ Configuration

The system uses Qwen3-8B model with the following default settings:
- **Model**: `Qwen/Qwen3-8B`
- **Max Model Length**: 32768 tokens
- **GPU Memory Utilization**: 0.7
- **VRAM Requirement**: ~16GB

## ğŸ“‹ Features

- **Document Processing**: Support for PDF, DOCX, and TXT files
- **OCR Integration**: DocLing with OCR for image-based PDFs
- **LLM Enhancement**: Qwen3-8B for advanced information extraction
- **REST API**: FastAPI-based web service
- **CLI Interface**: Command-line tool for batch processing

## ğŸ› ï¸ Usage

### API Usage
```bash
# Parse a single document
curl -X POST "http://localhost:8080/parse" \
  -H "accept: application/json" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@resume.pdf"

# Parse multiple documents
curl -X POST "http://localhost:8080/parse/batch" \
  -H "accept: application/json" \
  -H "Content-Type: multipart/form-data" \
  -F "files=@resume1.pdf" \
  -F "files=@resume2.pdf"
```

### CLI Usage
```bash
# Process a single file
python scripts/main.py resume.pdf

# Process a directory
python scripts/main.py /path/to/resumes/ --output results.json

# Check vLLM status
python scripts/main.py --check-vllm
```

## ğŸ“š Documentation

- **Detailed Documentation**: See `docs/README.md`
- **Setup Guide**: See `docs/SETUP.md`
- **Examples**: See `tests/example_usage.py`

## ğŸ” Testing

```bash
# Run comprehensive tests
python tests/test_qwen_resume.py

# Run basic tests
python tests/test_example.py

# See usage examples
python tests/example_usage.py
```

## ğŸ› Troubleshooting

1. **vLLM Server Issues**: Check GPU memory with `nvidia-smi`
2. **Import Errors**: Ensure you're running from the project root
3. **Port Conflicts**: Use `--vllm-port` and `--api-port` flags

## ğŸ“„ License

This project is open source and available under the MIT License. 